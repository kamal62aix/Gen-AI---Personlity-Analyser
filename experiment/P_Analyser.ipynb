{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3efa3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in /usr/local/python/3.12.1/lib/python3.12/site-packages (7.8.1)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: transformers in /usr/local/python/3.12.1/lib/python3.12/site-packages (4.53.2)\n",
      "Requirement already satisfied: torch in /home/codespace/.local/lib/python3.12/site-packages (2.7.0+cpu)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: prawcore<3,>=2.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from praw) (2.4.0)\n",
      "Requirement already satisfied: update_checker>=0.18 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in /home/codespace/.local/lib/python3.12/site-packages (from praw) (1.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (0.33.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install praw python-dotenv requests transformers torch pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d512d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def scrape_reddit_user(url):\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=os.getenv(\"REDDIT_CLIENT_ID\"),\n",
    "        client_secret=os.getenv(\"REDDIT_CLIENT_SECRET\"),\n",
    "        user_agent=os.getenv(\"REDDIT_USER_AGENT\")\n",
    "    )\n",
    "    \n",
    "    username = url.split(\"/user/\")[-1].strip(\"/\")\n",
    "    user = reddit.redditor(username)\n",
    "    \n",
    "    comments = []\n",
    "    posts = []\n",
    "    \n",
    "    # Scrape recent comments (limit: 100)\n",
    "    for comment in user.comments.new(limit=100):\n",
    "        comments.append(comment.body)\n",
    "    \n",
    "    # Scrape recent posts (limit: 50)\n",
    "    for submission in user.submissions.new(limit=50):\n",
    "        posts.append(submission.title + \" \" + (submission.selftext if submission.selftext else \"\"))\n",
    "    \n",
    "    return {\"comments\": comments, \"posts\": posts}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "161f6923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def generate_persona_groq(text_data):\n",
    "    API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer YOUR_GROQ_API_KEY\",  # Get free key: https://console.groq.com/\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analyze these Reddit posts/comments and generate a detailed User Persona.\n",
    "    Include demographics, interests, and personality traits (like Big Five or MBTI).\n",
    "    For each trait, cite the exact post/comment that supports it.\n",
    "\n",
    "    Example Output:\n",
    "    - **Demographic**: Male, 25-30 (from comment: \"As a guy in tech...\").\n",
    "    - **Interests**: AI, Python (from post: \"Built a Llama-3 fine-tuner\").\n",
    "    - **Personality**: High Openness (from comment: \"I love exploring new ideas\").\n",
    "\n",
    "    Input:\n",
    "    {text_data}\n",
    "    \"\"\"\n",
    "    \n",
    "    data = {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"model\": \"llama3-8b-8192\"  # or \"llama3-70b-8192\"\n",
    "    }\n",
    "    \n",
    "    response = requests.post(API_URL, headers=headers, json=data)\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "763ff915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_persona_to_file(username, persona_text):\n",
    "    with open(f\"{username}_persona.txt\", \"w\") as f:\n",
    "        f.write(persona_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3077dc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persona saved to Hungry-Move-6603_persona.txt\n"
     ]
    }
   ],
   "source": [
    "def save_persona_to_file(username, persona_text):\n",
    "    with open(f\"{username}_persona.txt\", \"w\") as f:\n",
    "        f.write(persona_text)\n",
    "\n",
    "def generate_persona(text):\n",
    "    # Example: just return the first 300 characters\n",
    "    return f\"Persona summary based on text:\\n{text[:300]}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    reddit_url = input(\"Enter Reddit Profile URL: \")\n",
    "\n",
    "    # Step 1: Scrape Data\n",
    "    user_data = scrape_reddit_user(reddit_url)\n",
    "    combined_text = \"\\n\".join(user_data[\"comments\"] + user_data[\"posts\"])\n",
    "\n",
    "    # Step 2: Generate Persona\n",
    "    persona = generate_persona(combined_text)\n",
    "\n",
    "    # Step 3: Save to File\n",
    "    username = reddit_url.split(\"/user/\")[-1].strip(\"/\")\n",
    "    save_persona_to_file(username, persona)\n",
    "\n",
    "    print(f\"Persona saved to {username}_persona.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0474525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/Gen-AI---Personlity-Analyser/experiment\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  # Shows where the file was saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4004e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
